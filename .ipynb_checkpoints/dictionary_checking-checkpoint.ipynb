{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Dictionary Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:22:32.665848Z",
     "start_time": "2018-10-31T21:22:32.660833Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import *\n",
    "import string\n",
    "import pickle\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:15:40.191977Z",
     "start_time": "2018-10-31T21:15:40.096184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load our data and try\n",
    "with open('modified_data/just_tags.txt', 'rb') as f:\n",
    "    just_tags = pickle.load(f)\n",
    "    \n",
    "with open('modified_data/just_words.txt', 'rb') as f:\n",
    "    just_words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:15:40.425333Z",
     "start_time": "2018-10-31T21:15:40.248777Z"
    }
   },
   "outputs": [],
   "source": [
    "words_train, words_test, tags_train, tags_test = train_test_split(just_words, just_tags, random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:15:40.501224Z",
     "start_time": "2018-10-31T21:15:40.426302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make hindi dictionary from training data becuase theres no phonetically typed hindi dictionary anywhere\n",
    "hin_dict = [w for i, w in enumerate(words_train) if tags_train[i] == 'HI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:21:44.347901Z",
     "start_time": "2018-10-31T21:21:44.341925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH\n"
     ]
    }
   ],
   "source": [
    "# How wordnets dictionary works:\n",
    "# Case insensitive so its good for our data\n",
    "if wordnet.synsets('glass'):\n",
    "    print('ENGLISH')\n",
    "else:\n",
    "    print('NOT ENGLISH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:30:11.453309Z",
     "start_time": "2018-10-31T20:30:11.438027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just check if emoticons with alphabets are present in the training set\n",
    "':P' in just_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:30:18.358755Z",
     "start_time": "2018-10-31T20:30:18.330496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ðŸ˜¡',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-)',\n",
       " 'ðŸ˜œ',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':/',\n",
       " ':(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':-(',\n",
       " ':/',\n",
       " ':@',\n",
       " ':@',\n",
       " ':(',\n",
       " ':-)',\n",
       " ';)',\n",
       " ':/',\n",
       " ':(',\n",
       " ':(',\n",
       " ';)',\n",
       " ':3',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':-(',\n",
       " ':-)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':-(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':(',\n",
       " ':(',\n",
       " ':(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':(',\n",
       " ':-(',\n",
       " ';)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " 'ðŸ˜¡',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':(',\n",
       " ';)',\n",
       " ':-/',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':(',\n",
       " ':(',\n",
       " ':)',\n",
       " 'ðŸ˜˜',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':/',\n",
       " ':-)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':@',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':/',\n",
       " ':-(',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-(',\n",
       " ':)',\n",
       " ';)',\n",
       " ':(',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ';)',\n",
       " ':-)',\n",
       " ':-)',\n",
       " ':-)',\n",
       " ':-)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " '=)',\n",
       " ';)',\n",
       " ':/',\n",
       " ';)',\n",
       " ':-)',\n",
       " ':3',\n",
       " ':@',\n",
       " ':(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':-/',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':/',\n",
       " ':-(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':/',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':/',\n",
       " ':)',\n",
       " ';)',\n",
       " ':(',\n",
       " ':)',\n",
       " ';)',\n",
       " ':(',\n",
       " ':-(',\n",
       " ':-(',\n",
       " ':-(',\n",
       " ':)',\n",
       " ';)',\n",
       " ':-)',\n",
       " ':)',\n",
       " ':-/',\n",
       " ':)',\n",
       " ':/',\n",
       " ';)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ';)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':-)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':(',\n",
       " ':(',\n",
       " ';)',\n",
       " ':-/',\n",
       " 'ðŸ˜¡',\n",
       " ':)',\n",
       " ';)',\n",
       " ';)',\n",
       " ';)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':)',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':(',\n",
       " 'ðŸ˜œ',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':(',\n",
       " ':(',\n",
       " ':)',\n",
       " ':-(',\n",
       " ';)',\n",
       " ':3',\n",
       " ':)',\n",
       " ';)',\n",
       " ':-(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-)',\n",
       " ';)',\n",
       " ':-/',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':3',\n",
       " ';)',\n",
       " ':(',\n",
       " ':(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':/',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':(',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-/',\n",
       " ';)',\n",
       " ':)',\n",
       " ':)',\n",
       " ':-)',\n",
       " ':(',\n",
       " ':-)',\n",
       " ':)',\n",
       " ';)',\n",
       " ';)',\n",
       " ';)',\n",
       " ';)',\n",
       " ':-)',\n",
       " ':-)',\n",
       " ':-(',\n",
       " ':-(',\n",
       " ';)',\n",
       " ':)',\n",
       " ':/',\n",
       " ':(',\n",
       " ':)',\n",
       " ';)',\n",
       " ';)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do emoticons look?\n",
    "[w for i, w in enumerate(just_words) if just_tags[i] == 'EMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:30:30.691535Z",
     "start_time": "2018-10-31T20:30:30.621724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EMT', 'EN', 'HI', 'UN'], dtype='<U3')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The 4 possible tags we need to classifiy for\n",
    "np.unique(tags_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet and Hindi Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:30:40.651506Z",
     "start_time": "2018-10-31T20:30:40.635813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classifier that uses wordnet's dictionary\n",
    "def classify_dictionary(words):\n",
    "    preds = []\n",
    "    for w in words:\n",
    "        if wordnet.synsets(w):\n",
    "            preds.append('EN')\n",
    "            \n",
    "        elif re.search('[a-zA-Z]', w) == None:\n",
    "            preds.append('EMT')\n",
    "            \n",
    "        elif w in hin_dict:\n",
    "            preds.append('HI')\n",
    "        \n",
    "        else:\n",
    "            preds.append('UN')\n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:33:13.062388Z",
     "start_time": "2018-10-31T20:31:58.071262Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_dict_train = classify_dictionary(words_train)\n",
    "preds_dict_test = classify_dictionary(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:27:27.778899Z",
     "start_time": "2018-10-31T21:27:27.774912Z"
    }
   },
   "outputs": [],
   "source": [
    "def classification_acc(true_y, pred_y):\n",
    "    classified = [True for i in range(len(true_y)) if true_y[i] == pred_y[i]]\n",
    "    return (np.sum(classified)/len(true_y))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T20:33:14.794980Z",
     "start_time": "2018-10-31T20:33:14.745833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification accuracy using just dictionaries is: 55.94523642547276 %\n",
      "Test classification accuracy using just dictionaries is: 52.33224933594817 %\n"
     ]
    }
   ],
   "source": [
    "print ('Training classification accuracy using just dictionaries is:', classification_acc(tags_train, preds_dict_train), '%')\n",
    "print ('Test classification accuracy using just dictionaries is:', classification_acc(tags_test, preds_dict_test), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking with the Twitter Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:18:53.275389Z",
     "start_time": "2018-10-31T21:18:53.269376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the twitter generated dictionary\n",
    "with open('dictionaries/dictionary_twitter.txt', 'rb') as f:\n",
    "    twitter_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:20:11.224714Z",
     "start_time": "2018-10-31T21:20:11.220724Z"
    }
   },
   "outputs": [],
   "source": [
    "just_keys = list(twitter_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:23:17.672707Z",
     "start_time": "2018-10-31T21:23:17.669718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the keys of punctuations and links\n",
    "invalid_chars = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:25:59.721728Z",
     "start_time": "2018-10-31T21:25:59.712752Z"
    }
   },
   "outputs": [],
   "source": [
    "twitter_dict_eng = [w for w in just_keys if not any([True for i in w if i in invalid_chars])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:27:18.334596Z",
     "start_time": "2018-10-31T21:27:18.318668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classifier that uses the Twitter dictionary dictionary\n",
    "def classify_dictionary_twitter(words):\n",
    "    preds = []\n",
    "    for w in words:\n",
    "        if w in twitter_dict_eng:\n",
    "            preds.append('EN')\n",
    "            \n",
    "        elif re.search('[a-zA-Z]', w) == None:\n",
    "            preds.append('EMT')\n",
    "            \n",
    "        elif w in hin_dict:\n",
    "            preds.append('HI')\n",
    "        \n",
    "        else:\n",
    "            preds.append('UN')\n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:29:36.802636Z",
     "start_time": "2018-10-31T21:27:52.925311Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_dict_train_tw = classify_dictionary_twitter(words_train)\n",
    "preds_dict_test_tw = classify_dictionary_twitter(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T21:30:11.423409Z",
     "start_time": "2018-10-31T21:30:11.372542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification accuracy using Twitter dictionaries is: 60.810282444500984 %\n",
      "Test classification accuracy using Twitter dictionaries is: 56.6591366084949 %\n"
     ]
    }
   ],
   "source": [
    "print ('Training classification accuracy using Twitter dictionaries is:', classification_acc(tags_train, preds_dict_train_tw), '%')\n",
    "print ('Test classification accuracy using Twitter dictionaries is:', classification_acc(tags_test, preds_dict_test_tw), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy has slightly improved with a dictionary more suitable for the task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
